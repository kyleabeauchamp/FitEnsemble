{
 "metadata": {
  "name": "Tutorial 1.  Linear Virtual Biasing Potential"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "Modelling Conformational Ensembles with fit_ensemble\n==================================================\n\nIntroduction\n------------\n\nIn this tutorial, we use Linear Virtual Biasing Potential (LVBP) to infer the conformational ensemble of tri-alanine.  LVBP requires three inputs:\n\n* A set of conformations to be used as a \"starting\" guess for the ensemble: $x_i$\n\n* A set of experimental ``measurements`` and their ``uncertainties``\n\n* The predicted experimental observables (``predictions``) at each conformation.\n\nLVBP combines `measurements`, `uncertainties`, and `predictions` using Bayesian inference to produce a conformational ensemble that best agrees with your data.  \n\n\nImporting fit_ensemble\n----------------------\n\nWe first import some Python libraries used in the tutorial"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "import numpy as np\nimport pandas\nimport pymc \nimport matplotlib.pyplot as plt\nfrom fit_ensemble import lvbp, example_loader",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "Load input data\n---------------\n\nWe will use a single $^3J(H^N H^\\alpha )$ $ \\;$  NMR measurement to reweight molecular dynamics simulations performed in the Amber ff96 forcefield.  Note that a single experiment is *not* sufficient to correct the forcefield bias in ff96.  However, the single-experiment calculation illustrates the key points and runs in under a minute.  \n\nWe next load the data used to connect simulation and experiment:  "
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "measurements, predictions, uncertainties = example_loader.load_alanine()",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "In addition to the quantities *necessary* for the LVBP calculation, it's also useful to examine additional structural properties such as the $\\phi$ and $\\psi$ backbone torsions.  The follow code loads the backbone torsion angles $\\phi$ and $\\psi$ for the internal alanine in tri-alanine.  In addition, we have also calculated the conformation states of each snapshot ($\\alpha$, $\\beta$, or $PP_{II}$ $\\;$), using the state definitions from [1].  "
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "phi, psi, assignments, indicators = example_loader.load_alanine_dihedrals()",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "We also need to define a number of parameters for LVBP calculation.  The first is the name of the HDF5 file used to store the Markov chain Monte Carlo (MCMC) trace:"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "pymc_filename = \"./trialanine_MCMC.h5\"",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "We also need to define the MCMC parameters.  These include the number of MCMC samples to generate, the amount by which to thin or subsample the traces, and the number of samples to discard during the equilibration:"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "num_samples = 25000  # Generate 25,000 MCMC samples\nthin = 25  # Subsample (i.e. thin) the MCMC traces by 25X to ensure independent samples\nburn = 5000  # Discard the first 5000 samples as \"burn-in\"\n",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "We also need to define the amount of regularization to use.  We will use maximum entropy regularization, which prefers ensembles that weight each conformation uniformly:  \n\n$$\\log P(\\alpha) = \\lambda \\sum_j \\pi_j(\\alpha) \\log \\pi_j(\\alpha)$$\n\nWith a large value of `regularization_strength` ($\\lambda \\;$), we strongly prefer the raw MD ensemble, which gives equal weight to each conformation."
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "regularization_strength = 5.0  # How strongly do we prefer a \"uniform\" ensemble (the \"raw\" MD)? ",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "At this point, we are almost ready to go.  We need to create an LVBP object using our simulation and experimental data:"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "lvbp_model = lvbp.MaxEnt_LVBP(predictions, measurements, uncertainties, regularization_strength)",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "We are now good to go!  We now sample the likelihood of models given our data, saving the results to our HDF5 database on disk:"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "lvbp_model.sample(num_samples, thin=thin, burn=burn, filename=pymc_filename)",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "Any calculation performed using Markov chain Monte Carlo should be checked for convergence.  There are many sophisticated tests of convergence, but a powerful heuristic is to graphically examine the trace of model parameters $\\alpha$.  A properly sampled and thinned MCMC trace should look like white noise."
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "a0 = lvbp_model.mcmc.trace(\"alpha\")[:,0]\nplt.plot(a0)\nplt.title(\"MCMC trace of alpha\")",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "The single most important result in an LVBP model are the maximum a posteriori populations.  These are essentially the *most likely* conformational populations for each conformation in your prior ensemble.  The `accumulate_populations()` member function calculates these populations for you:"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "p = lvbp_model.accumulate_populations()",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "You should now check the agreement between the simulation and experiment.  We check both the raw MD simulation and the LVBP model.  "
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "print(\"Reduced chi squared of raw MD: %f\" % np.mean(((predictions.mean(0) - measurements) / uncertainties)**2))\nprint(\"Reduced chi squared of LVBP: %f\" % np.mean(((predictions.T.dot(p) - measurements) / uncertainties)**2))",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "At this point, we can dig deeper into understanding the results of our calculation.  Because we are looking at a single residue, we can visualize the relevant populations using a Ramachandran plot of the $\\phi$ and $\\psi$ torsion angles.  We first look at the raw MD simulation."
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "h,x,y = np.histogram2d(phi,psi, bins=100)\nextent = [-180,180,-180,180]\nplt.figure()\nplt.xlabel(\"$\\phi$\")\nplt.ylabel(\"$\\psi$\")\nplt.title(r\"MD Population Density\")\nplt.imshow(h.T,origin='lower',extent=extent)\nplt.xlim(-180,180)\nplt.ylim(-180,180)\n",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "We now look at the reweighted (i.e. LVBP) ensemble.  You will notice that the $PP_{II}$ $\\;$ basin has increased its population, while the $\\beta$ basin has decreased its population.  Thus, we have *inferred* that the Amber ff96 forcefield *biases* simulations towards the $\\beta$ conformational state; this bias was partially removed by LVPB.  "
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "h,x,y = np.histogram2d(phi,psi,bins=100,weights=p)\nplt.figure()\nplt.xlabel(\"$\\phi$\")\nplt.ylabel(\"$\\psi$\")\nplt.title(r\"Reweighted Population Density\")\nplt.imshow(h.T,origin='lower',extent=extent)\nplt.xlim(-180,180)\nplt.ylim(-180,180)",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "",
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}