{
 "metadata": {
  "name": "Tutorial2"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Tracing Additional Random Variables\n",
      "==================================="
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Often, we would like to keep track of (i.e. `trace`) additional quantities while we sample the model likelihoods.  Tracing these quantities allows us to characterize the posterior distribution of arbitrary structural features.  For the case of tri-alanine, we would like to track the populations of each of the four conformational states.  As before, we start by constructing and sampling an LVBP model."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "from fitensemble import lvbp, example_loader\n",
      "\n",
      "predictions, measurements, uncertainties = example_loader.load_alanine()\n",
      "phi, psi, assignments, indicators = example_loader.load_alanine_dihedrals()\n",
      "\n",
      "num_samples = 20000  # Generate 20,000 MCMC samples\n",
      "thin = 25  # Subsample (i.e. thin) the MCMC traces by 25X to ensure independent samples\n",
      "burn = 5000  # Discard the first 5000 samples as \"burn-in\"\n",
      "\n",
      "regularization_strength = 3.0  # How strongly do we prefer a \"uniform\" ensemble (the \"raw\" MD)? \n",
      "\n",
      "lvbp_model = lvbp.MaxEnt_LVBP(predictions, measurements, uncertainties, regularization_strength)\n",
      "lvbp_model.sample(num_samples, thin=thin, burn=burn)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " \r",
        "[****************100%******************]  25000 of 25000 complete"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Trace Observable\n",
      "----------------\n",
      "\n",
      "Now we run the new code that outputs the trace of an additional \"observable\".  We simply call `lvbp_model.trace_observable()`.  This function takes a numpy array as input; here we input the transpose of the matrix of state indicators.  \n",
      "\n",
      "Thus, for each conformational ensemble in our MCMC trace, we calculate the population of the four torsional states:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "state_pops_trace = lvbp_model.trace_observable(indicators.T)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Estimate Average Properties\n",
      "---------------------------\n",
      "\n",
      "We have calculated a trace of the state populations for each conformational ensemble in the MCMC chain.  We first characterize the average (over all MCMC samples) state populations.  We also look at the state populations of the raw MD simulation."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "state_pops_raw = np.bincount(assignments) / float(len(assignments))\n",
      "state_pops = state_pops_trace.mean(0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We would like to view the conformational populations as a table.  We use the pandas library to construct a tabular view of the populations:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pd.DataFrame([state_pops_raw,state_pops],columns=[r\"$PP_{II}$\",r\"$\\beta$\",r\"$\\alpha_r$\",r\"$\\alpha_l$\"],index=[\"Raw (MD)\", \"LVBP\"])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>$PP_{II}$</th>\n",
        "      <th>$\\beta$</th>\n",
        "      <th>$\\alpha_r$</th>\n",
        "      <th>$\\alpha_l$</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>Raw (MD)</th>\n",
        "      <td> 0.438756</td>\n",
        "      <td> 0.509199</td>\n",
        "      <td> 0.049334</td>\n",
        "      <td> 0.002710</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>LVBP</th>\n",
        "      <td> 0.557897</td>\n",
        "      <td> 0.388415</td>\n",
        "      <td> 0.050881</td>\n",
        "      <td> 0.002807</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "          $PP_{II}$   $\\beta$  $\\alpha_r$  $\\alpha_l$\n",
        "Raw (MD)   0.438756  0.509199    0.049334    0.002710\n",
        "LVBP       0.557897  0.388415    0.050881    0.002807"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Estimate Uncertainties\n",
      "----------------------\n",
      "\n",
      "It is also useful to look at the uncertainties associated with each of the state populations:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "state_uncertainties = state_pops_trace.std(0)\n",
      "pd.DataFrame([state_uncertainties],columns=[r\"$PP_{II}$\",r\"$\\beta$\",r\"$\\alpha_r$\",r\"$\\alpha_l$\"],index=[\"LVBP\"])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>$PP_{II}$</th>\n",
        "      <th>$\\beta$</th>\n",
        "      <th>$\\alpha_r$</th>\n",
        "      <th>$\\alpha_l$</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>LVBP</th>\n",
        "      <td> 0.031942</td>\n",
        "      <td> 0.032518</td>\n",
        "      <td> 0.000568</td>\n",
        "      <td> 0.000013</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "      $PP_{II}$   $\\beta$  $\\alpha_r$  $\\alpha_l$\n",
        "LVBP   0.031942  0.032518    0.000568    0.000013"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A Better way to Evaluate Model Quality\n",
      "--------------------------------------\n",
      "\n",
      "In the first tutorial, we evaluated model quality using the reduced $\\chi^2$.  To calculate the reduced $\\chi^2$, we first calculated the posterior average populations.  Now that we know how to use our MCMC samples, however, we should estimate the model quality using a more \"Bayesian\" approach.  To do so, we are going to iterate over the MCMC samples of conformational populations to calculate the reduced $\\chi^2$ for every MCMC sample.  "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "chi2 = []\n",
      "for pi in lvbp_model.iterate_populations():\n",
      "    mu = predictions.T.dot(pi)\n",
      "    chi2.append((((mu - measurements) / uncertainties)**2).mean(0))\n",
      "\n",
      "chi2_MCMC = np.mean(chi2)\n",
      "p = lvbp_model.accumulate_populations()\n",
      "mu = predictions.T.dot(p)\n",
      "chi2_AVE = (((mu - measurements) / uncertainties)**2).mean(0)\n",
      "\n",
      "pd.DataFrame([[chi2_MCMC, chi2_AVE]],columns=[\"MCMC Sampled\", \"Posterior Average Populations\"],index=[\"Reduced $\\chi^2$\"])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>MCMC Sampled</th>\n",
        "      <th>Posterior Average Populations</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>Reduced $\\chi^2$</th>\n",
        "      <td> 0.452694</td>\n",
        "      <td> 0.023361</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "                  MCMC Sampled  Posterior Average Populations\n",
        "Reduced $\\chi^2$      0.452694                       0.023361"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Notice that the MCMC sampled reduced $\\chi^2$ is approximately equal to one, while the posterior average result is approximately equal to zero.  A value of reduced $\\chi^2$ near zero suggests an overfit model.  Our model, however, is not overfit; we just need to calculate the reduced $\\chi^2$ in a \"Bayesian\" way.  \n",
      "\n",
      "You've finished this tutorial.  In your own research, you can use a similar approach to characterize quantities like RMSD, radius of gyration, distances between atoms, side chain torsions, etc.  \n",
      "\n",
      "Continue on to the third tutorial [here].  \n",
      "\n",
      "References\n",
      "----------\n",
      "\n",
      "* Beauchamp, K. A., Das, R. , and Pande, V. S.  Inferring Conformational Ensembles from Noisy Experiments.  In Prep.\n",
      "\n",
      "* Sosnick et al.  Helix, sheet, and polyproline II frequencies and strong nearest neighbor effects in a restricted coil library.  Biochemistry, 2005."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}
