{
 "metadata": {
  "name": "Tutorial4"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "File Input and Output\n",
      "=====================\n",
      "\n",
      "In this tutorial, we discuss saving an LVBP model to disk for later use.  We repeat the same calculations as in the previous tutorials, but this time save the model to disk for later use.  \n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "from fit_ensemble import lvbp, example_loader\n",
      "\n",
      "measurements, predictions, uncertainties = example_loader.load_alanine()\n",
      "phi, psi, assignments, indicators = example_loader.load_alanine_dihedrals()\n",
      "\n",
      "num_samples = 25000  # Generate 25,000 MCMC samples\n",
      "thin = 25  # Subsample (i.e. thin) the MCMC traces by 25X to ensure independent samples\n",
      "burn = 5000  # Discard the first 5000 samples as \"burn-in\"\n",
      "\n",
      "regularization_strength = 3.0  # How strongly do we prefer a \"uniform\" ensemble (the \"raw\" MD)? "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Saving to HDF5\n",
      "--------------\n",
      "\n",
      "The following code builds a model, just like before.  However, we now pass a filename argument when we begin the MCMC sampling.  This tells PyMC to save the results to disk as an HDF5 database.  This is useful for situations where the entire MCMC trace cannot fit in system memory.  "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lvbp_model = lvbp.MaxEnt_LVBP(predictions, measurements, uncertainties, regularization_strength)\n",
      "\n",
      "pymc_filename = \"trialanine.h5\"\n",
      "lvbp_model.sample(num_samples, thin=thin, burn=burn,filename=pymc_filename)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The HDF5 database file trialanine.h5 contains all components necessary to work with your LVBP model.  This includes\n",
      "\n",
      "* `predictions`\n",
      "* `measurements`\n",
      "* `uncertainties`\n",
      "* The MCMC trace\n",
      "\n",
      "Loading from HDF5\n",
      "-----------------\n",
      "\n",
      "To load an HDF5 file from disk, use the load() function:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lvbp_model = lvbp.MaxEnt_LVBP.load(\"./trialanine.h5\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As we did previously, this model can be used to calculate the MAP conformational populations (`p`) or a trace (`state_pops_trace`) of an arbitrary observable:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "p = lvbp_model.accumulate_populations()\n",
      "state_pops_trace = lvbp_model.trace_observable(indicators.T)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}